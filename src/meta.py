from collections import OrderedDict

TITLE = "Beau parleur ü•ñü•ñü•ñ : plateforme d'exp√©rimentation de mod√®le g√©n√©ratif en langue fran√ßaise"

HEADER1 = "Principes et objectifs"
HEADER2 = "M√©thodes de g√©n√©ration"
HEADER3 = "Exp√©rimentons ! "

body = OrderedDict()

body[HEADER1] = []
body[HEADER1].append("Les mod√®les g√©n√©ratifs sur base des [Transformers](https://fr.wikipedia.org/wiki/Transformeur) ont permis une avanc√©e notable en ce qui concerne la compr√©hension automatis√©e du langage. Ceci a permis des innovations de rupture dans plusieurs domaines, notamment dans la qualification de texte. Mais _quid_ du domaine cr√©atif ? C'est ici qu'interviennent les mod√®les g√©n√©ratifs tels que [GPT](https://openai.com/blog/language-unsupervised/),[GPT-2](https://openai.com/blog/better-language-models/) ou encore le r√©cent - et r√©volutionnaire - [GPT3](https://arxiv.org/abs/2005.14165).")

body[HEADER1].append("Ces mod√®les sont pr√©-entra√Æn√©s : ceci veut dire que les param√®tres qui les d√©terminent ont d√©j√† √©t√© appris par une grande volum√©trie de donn√©es. Ainsi, libre √† l'utilisateur de ce mod√®le de l'utiliser directement, ou bien de  _sp√©cialiser_ le mod√®le en ajoutant une couche d'apprentissage suppl√©mentaire (on parle alors de _fine-tuning_)")

body[HEADER1].append("Ceci √©tant, les mod√®les g√©n√©ratifs sont biais√©s en ce qui concerne les langues trait√©es. Ainsi, la donn√©e ayant servi √† cr√©er les mod√®les g√©n√©ratifs GPT est principalement de langue anglaise, ce qui peut avoir tendance √† entraver l'adoption de l'intelligence artificielle dans le monde dans le monde.")


body[HEADER1].append("La langue fran√ßaise n'est pas √©pargn√©e par une telle pr√©pond√©rance de la langue anglaise. Notons n√©anmoins la remarquable initiative [PiaF](https://aclanthology.org/2020.lrec-1.673/), initiative issue de l'[EtaLab](https://www.etalab.gouv.fr/politique-de-la-donnee), plateforme gouvernementale de partage de la donn√©e.")

body[HEADER1].append("Fort heureusement, la langue fran√ßaise ne se r√©sume pas au territoire hexagonal ! Ainsi Antoine Louis a pr√©-entra√Æn√© un mod√®le GPT-2 sur pr√®s de 60Gb de donn√©e fran√ßaise et a mis √† disposition ce mod√®le sur Hugging Face. Ce mod√®le se nomme [BelGPT-2](https://github.com/antoiloui/belgpt2), et c'est celui-ci que nous utiliserons.")


body[HEADER2] = []
body[HEADER2].append("Nous allons explorer 3 m√©thodes de g√©n√©ration. Les personnes int√©ress√©es pourront se r√©f√©rer au [post de blog de Hugging Face sur les mod√®les g√©n√©ratif](https://huggingface.co/blog/how-to-generate)")
body[HEADER2].append("En bref, un mod√®le de type GPT2 est __auto-r√©gressif__: conditionnellement √† un mot que l'on prononce au sein d'une phrase, le mod√®le apprend √† d√©terminer le mot suivant le plus probable.")

body[HEADER2].append("Trois m√©thodes de g√©n√©rations sont possibles √† partir de ce mod√®le")
body[HEADER2].append(" - Une g√©n√©ration _greedy_ : les mots g√©n√©r√©s sont les mots les plus probables. Cette m√©thode n'a pas l'avantage de la diversit√©, car il n'en d√©coule qu'un seul sc√©nario possible.")
body[HEADER2].append(" - Une g√©n√©ration par faisceaux, dite _beam search_ : les mots g√©n√©r√©s font partie d'une arborescence de mots les plus probables.")
body[HEADER2].append(" - Une g√©n√©ration par √©chantillonage, ou une g√©n√©ration _sampling_ : On √©chantillone suivant la loi de probabilit√© calibr√©e par le mod√®le.")

body[HEADER3] = []
body[HEADER3].append("Il est grand temps d'exp√©rimenter la g√©n√©ration et de se laisser entra√Æner par les diff√©rentes propositions")
body[HEADER3].append("‚ö†Ô∏è  Suivant les param√®tres d'entr√©e, les textes g√©n√©r√©s peuvent √™tre vulgaires, voire offensants. Ceux-ci peuvent √™tre instructifs en ce qui concerne toxicit√© actuelle des discours sur Internet : en effet, la donn√©e sur laquelle ces mod√®les sont appris   ‚ö†Ô∏è ")
